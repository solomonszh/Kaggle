{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:00:30.421501Z",
     "start_time": "2019-12-15T07:00:11.522118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:00:34.353797Z",
     "start_time": "2019-12-15T07:00:30.424804Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:16:13.082563Z",
     "start_time": "2019-12-15T07:16:13.070837Z"
    }
   },
   "outputs": [],
   "source": [
    "myfavouritenumber = 42\n",
    "seed = myfavouritenumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:01:28.174879Z",
     "start_time": "2019-12-15T07:00:34.365231Z"
    }
   },
   "outputs": [],
   "source": [
    "energy_train = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\train.csv')\n",
    "weather_train = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\weather_train.csv')\n",
    "building = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\building_metadata.csv')\n",
    "energy_test = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\test.csv')\n",
    "weather_test = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\weather_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.timestamp = pd.to_datetime(energy.timestamp)\n",
    "energy.meter = energy.meter.astype('category')\n",
    "energy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of building counts\n",
    "g1 = energy.building_id.value_counts()\n",
    "plt.hist(g1.values,bins=100)\n",
    "plt.xlabel('Total rows of a building id')\n",
    "plt.ylabel('Number building ids')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy['meter'].replace({0:\"Electricity\",1:\"ChilledWater\",2:\"Steam\",3:\"HotWater\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of meter\n",
    "g2 = energy.meter.value_counts()\n",
    "plt.bar(g2.index,g2.values)\n",
    "plt.xlabel('Meter Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check outlier\n",
    "g3 = energy[['meter','meter_reading']]\n",
    "g3['meter_reading'] = np.log1p(g3['meter_reading'])\n",
    "sns.boxplot(x='meter',y='meter_reading',data=g3)\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(energy[energy['meter'] == \"Electricity\"]['meter_reading'])\n",
    "plt.title(\"Boxplot of Meter Reading Variable for the Meter Type: Electricity\")\n",
    "# We can see a few outliers here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(energy[energy['meter'] == \"ChilledWater\"]['meter_reading'])\n",
    "plt.title(\"Boxplot of Meter Reading Variable for the Meter Type: Electricity\")\n",
    "# Not many outliers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(energy[energy['meter'] == \"HotWater\"]['meter_reading'])\n",
    "plt.title(\"Boxplot of Meter Reading Variable for the Meter Type: Electricity\")\n",
    "# We can see a single value that is way off from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(energy[energy['meter'] == \"Steam\"]['meter_reading'])\n",
    "plt.title(\"Boxplot of Meter Reading Variable for the Meter Type: Electricity\") \n",
    "#No outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(energy['meter_reading']),kde=False)\n",
    "plt.title(\"Distribution of Log of Meter Reading Variable\")\n",
    "# Lot of 0 values as can be seen from the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.timestamp = pd.to_datetime(weather.timestamp)\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = weather.drop(['site_id','timestamp'],axis=1).corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(h,annot=True,center=0,cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['air_temperature','cloud_coverage','dew_temperature','precip_depth_1_hr','sea_level_pressure','wind_speed']\n",
    "for ind,col in enumerate(weather[cols]):\n",
    "    plt.figure(ind)\n",
    "    sns.distplot(weather[col].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of building age\n",
    "i1 = building_info.year_built.value_counts()\n",
    "plt.bar(i1.index,i1.values)\n",
    "plt.xlabel('Year Built')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = building_info.primary_use.value_counts()\n",
    "plt.barh(i2.index,i2.values)\n",
    "plt.xlabel('Building Primary Use')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment by Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data prep for Modeling\n",
    "#Target variable: meter_reading\n",
    "#Encode primary_use variables for modeling\n",
    "#Convert the timestamp to datetime\n",
    "\n",
    "def dt_parts(df,dt_col):\n",
    "    if(df[dt_col].dtype=='O'):\n",
    "        df[dt_col] = pd.to_datetime(df[dt_col])\n",
    "    df['year'] = df[dt_col].dt.year.astype(np.int16)\n",
    "    df['month'] = df[dt_col].dt.month.astype(np.int8)\n",
    "    df['day'] = df[dt_col].dt.day.astype(np.int8)\n",
    "    df['hour'] = df[dt_col].dt.hour.astype(np.int8)\n",
    "    df['minute'] = df[dt_col].dt.minute.astype(np.int8)\n",
    "    df['second'] = df[dt_col].dt.second.astype(np.int8)\n",
    "    return df\n",
    "\n",
    "#optimizing the column types to consume less space\n",
    "def df_type_optimize(df):\n",
    "    df['building_id'] = df['building_id'].astype(np.uint16)\n",
    "    df['meter'] = df['meter'].astype(np.uint8)\n",
    "    df['site_id'] = df['site_id'].astype(np.uint8)\n",
    "    df['square_feet'] = df['square_feet'].astype(np.uint32)\n",
    "    \n",
    "    df['year_built'] = df['year_built'].astype(np.uint16)\n",
    "    df['floor_count'] = df['floor_count'].astype(np.uint8)\n",
    "    \n",
    "    df['air_temperature'] = df['air_temperature'].astype(np.int16)\n",
    "    df['cloud_coverage'] = df['cloud_coverage'].astype(np.int16)\n",
    "    df['dew_temperature'] = df['dew_temperature'].astype(np.int16)\n",
    "    df['precip_depth_1_hr'] = df['precip_depth_1_hr'].astype(np.int16)\n",
    "    df['sea_level_pressure'] = df['sea_level_pressure'].astype(np.int16)\n",
    "    df['wind_direction'] = df['wind_direction'].astype(np.int16)\n",
    "    df['wind_speed'] = df['wind_speed'].astype(np.int16)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parts(energy,'timestamp')\n",
    "dt_parts(weather,'timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.groupby(['meter','month'])['meter_reading'].agg(['max','mean','median','count','std'])\n",
    "# We can see that only Steam meter has very high meter_reading values as compared to other types of meters.\n",
    "# We can see that the average electricity meter_reading does not vary much across the months.\n",
    "# Average Hot Water meter_reading is relatively less from April to October Months.\n",
    "# Average Steam meter_reading is way higher from March to June as compared to the other months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "building_info['primary_use'].value_counts().sort_values().plot(kind='bar')\n",
    "plt.title(\"Count of Primary_Use Variable in the Metadata table\")\n",
    "plt.xlabel(\"Primary Use\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=90)\n",
    "# Education, Office, Entertainment/Public Assembly, Public Services, Lodging/Residential form the bulk of Primary Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(building_info['square_feet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info['square_feet'] = np.log1p(building_info['square_feet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(building_info['square_feet'])\n",
    "plt.title(\"Distribution of Square Feet variable of Metadata Table\")\n",
    "plt.xlabel(\"Area in Square Feet\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# Looks like a normal distribution distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info.groupby('primary_use')['square_feet'].agg(['mean','median','count']).sort_values(by='count')\n",
    "# Parking has the highest average are although the count is less.\n",
    "# Education has the highest count as can be seen in the countplot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info['year_built'].value_counts().sort_values().plot(kind='bar',figsize=(15,6))\n",
    "plt.xlabel(\"Year Built\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Year Built Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info['floor_count'].value_counts(dropna=False).sort_index().plot(kind='bar',figsize=(8,6))\n",
    "plt.xlabel(\"Number of Floors\")\n",
    "plt.ylabel(\"Count of Buildings\")\n",
    "# Lot of missing values here as well\n",
    "# Maximum number of floors is 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info.groupby('floor_count')['square_feet'].agg(['count','mean','median']).sort_values(by='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info.groupby('primary_use')['square_feet'].agg(['count','mean','median']).sort_values(by='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_info['year_built'].fillna(-999, inplace=True)\n",
    "building_info['year_built'] = building_info['year_built'].astype('int16')\n",
    "building_info['floor_count'].fillna(-999, inplace=True)\n",
    "building_info['floor_count'] = building_info['floor_count'].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative-All "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:05:32.259421Z",
     "start_time": "2019-12-15T07:01:28.209326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = energy_train\n",
    "df_test = energy_test\n",
    "\n",
    "building = building\n",
    "le = LabelEncoder()\n",
    "building.primary_use = le.fit_transform(building.primary_use)\n",
    "\n",
    "weather_train = weather_train\n",
    "weather_test = weather_test\n",
    "\n",
    "weather_train.drop([\"sea_level_pressure\", \"wind_direction\", \"wind_speed\"], axis=1, inplace=True)\n",
    "weather_test.drop([\"sea_level_pressure\", \"wind_direction\", \"wind_speed\"], axis=1, inplace=True)\n",
    "\n",
    "weather_train = weather_train.groupby(\"site_id\").apply(lambda group: group.interpolate(limit_direction=\"both\"))\n",
    "weather_test = weather_test.groupby(\"site_id\").apply(lambda group: group.interpolate(limit_direction=\"both\"))\n",
    "\n",
    "df_train = df_train.merge(building, on=\"building_id\")\n",
    "df_train = df_train.merge(weather_train, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
    "df_train = df_train[~((df_train.site_id==0) & (df_train.meter==0) & (df_train.building_id <= 104) & (df_train.timestamp < \"2016-05-21\"))]\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#fixing site_id 0\n",
    "df_train.loc[df_train['site_id']==0, 'meter_reading'] = df_train.loc[df_train['site_id']==0, 'meter_reading'] * 0.2931\n",
    "\n",
    "df_train.timestamp = pd.to_datetime(df_train.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "df_train[\"log_meter_reading\"] = np.log1p(df_train.meter_reading)\n",
    "\n",
    "df_test = df_test.merge(building, on=\"building_id\")\n",
    "df_test = df_test.merge(weather_test, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "df_test.timestamp = pd.to_datetime(df_test.timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "del building, le\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:05:32.350701Z",
     "start_time": "2019-12-15T07:05:32.277543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code from https://www.kaggle.com/caesarlupum/ashrae-start-here-a-gentle-introduction \n",
    "# Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "# function to calculate evaluation metric\n",
    "def rmsle(y_true: pd.Series, y_predict: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate root mean squared log error\n",
    "    :param y_true:\n",
    "    :param y_predict:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.sqrt(msle(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:06:32.821845Z",
     "start_time": "2019-12-15T07:05:32.359435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 663.15 Mb (67.6% reduction)\n",
      "Mem. usage decreased to 1312.28 Mb (67.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "\n",
    "df_train[\"hour\"] = df_train.timestamp.dt.hour\n",
    "df_train[\"weekday\"] = df_train.timestamp.dt.weekday\n",
    "\n",
    "df_test[\"hour\"] = df_test.timestamp.dt.hour\n",
    "df_test[\"weekday\"] = df_test.timestamp.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:08:57.607289Z",
     "start_time": "2019-12-15T07:07:06.384297Z"
    }
   },
   "outputs": [],
   "source": [
    "df_building_meter = df_train.groupby([\"building_id\", \"meter\"]).agg(mean_building_meter=(\"log_meter_reading\", \"mean\"),\n",
    "                                                             median_building_meter=(\"log_meter_reading\", \"median\")).reset_index()\n",
    "\n",
    "df_train = df_train.merge(df_building_meter, on=[\"building_id\", \"meter\"])\n",
    "df_test = df_test.merge(df_building_meter, on=[\"building_id\", \"meter\"])\n",
    "\n",
    "df_building_meter_hour = df_train.groupby([\"building_id\", \"meter\", \"hour\"]).agg(mean_building_meter=(\"log_meter_reading\", \"mean\"),\n",
    "                                                                                median_building_meter=(\"log_meter_reading\", \"median\")).reset_index()\n",
    "\n",
    "df_train = df_train.merge(df_building_meter_hour, on=[\"building_id\", \"meter\", \"hour\"])\n",
    "df_test = df_test.merge(df_building_meter_hour, on=[\"building_id\", \"meter\", \"hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:08:57.725319Z",
     "start_time": "2019-12-15T07:08:57.638864Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_lag_features(df, window):\n",
    "    \"\"\"\n",
    "    Creating lag-based features looking back in time.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_cols = [\"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\"]\n",
    "    df_site = df.groupby(\"site_id\")\n",
    "    \n",
    "    df_rolled = df_site[feature_cols].rolling(window=window, min_periods=0)\n",
    "    \n",
    "    df_mean = df_rolled.mean().reset_index().astype(np.float16)\n",
    "    df_median = df_rolled.median().reset_index().astype(np.float16)\n",
    "    df_min = df_rolled.min().reset_index().astype(np.float16)\n",
    "    df_max = df_rolled.max().reset_index().astype(np.float16)\n",
    "    df_std = df_rolled.std().reset_index().astype(np.float16)\n",
    "    df_skew = df_rolled.skew().reset_index().astype(np.float16)\n",
    "    \n",
    "    for feature in feature_cols:\n",
    "        df[f\"{feature}_mean_lag{window}\"] = df_mean[feature]\n",
    "        df[f\"{feature}_median_lag{window}\"] = df_median[feature]\n",
    "        df[f\"{feature}_min_lag{window}\"] = df_min[feature]\n",
    "        df[f\"{feature}_max_lag{window}\"] = df_max[feature]\n",
    "        df[f\"{feature}_std_lag{window}\"] = df_std[feature]\n",
    "        df[f\"{feature}_skew_lag{window}\"] = df_std[feature]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:32:00.074819Z",
     "start_time": "2019-12-15T07:32:00.055787Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6a0acf4706ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweather_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweather_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mweather_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweather_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather_train' is not defined"
     ]
    }
   ],
   "source": [
    "weather_train.timestamp = pd.to_datetime(weather_train.timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:32:14.033430Z",
     "start_time": "2019-12-15T07:32:13.754543Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_test.timestamp = pd.to_datetime(weather_test.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:09:24.594724Z",
     "start_time": "2019-12-15T07:08:58.033498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_train = create_lag_features(weather_train, 18)\n",
    "weather_train.drop([\"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\"], axis=1, inplace=True)\n",
    "\n",
    "df_train = df_train.merge(weather_train, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
    "\n",
    "del weather_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:09:24.641785Z",
     "start_time": "2019-12-15T07:09:24.605914Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"building_id\",\n",
    "    \"primary_use\",\n",
    "    \"meter\",\n",
    "    \"weekday\",\n",
    "    \"hour\"\n",
    "]\n",
    "\n",
    "all_features = [col for col in df_train.columns if col not in [\"timestamp\", \"site_id\", \"meter_reading\", \"log_meter_reading\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:29:49.890849Z",
     "start_time": "2019-12-15T07:16:21.919627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c31572a18c49b9a88cd659ed2d9a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='site_id', max=16, style=ProgressStyle(description_width='initâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold CV for site_id: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.640528\tvalid_1's rmse: 0.636799\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.621412\tvalid_1's rmse: 0.636539\n",
      "Site Id: 0 , Fold: 1 , RMSE: 0.6357694905629656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.471422\tvalid_1's rmse: 0.838763\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's rmse: 0.48755\tvalid_1's rmse: 0.837274\n",
      "Site Id: 0 , Fold: 2 , RMSE: 0.8379867462065811\n",
      "\n",
      "Site Id: 0 , CV RMSE: 0.7437824386030453 \n",
      "\n",
      "2 fold CV for site_id: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.599865\tvalid_1's rmse: 0.977308\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's rmse: 0.59147\tvalid_1's rmse: 0.975738\n",
      "Site Id: 1 , Fold: 1 , RMSE: 0.9774293510378093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.740553\tvalid_1's rmse: 0.758059\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttraining's rmse: 0.70489\tvalid_1's rmse: 0.75613\n",
      "Site Id: 1 , Fold: 2 , RMSE: 0.7553552259600743\n",
      "\n",
      "Site Id: 1 , CV RMSE: 0.8734787773779319 \n",
      "\n",
      "2 fold CV for site_id: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.732258\tvalid_1's rmse: 0.809412\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's rmse: 0.72581\tvalid_1's rmse: 0.807701\n",
      "Site Id: 2 , Fold: 1 , RMSE: 0.798330689926289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.635472\tvalid_1's rmse: 0.935168\n",
      "[202]\ttraining's rmse: 0.584582\tvalid_1's rmse: 0.931301\n",
      "Early stopping, best iteration is:\n",
      "[266]\ttraining's rmse: 0.563147\tvalid_1's rmse: 0.928987\n",
      "Site Id: 2 , Fold: 2 , RMSE: 0.9255390519386634\n",
      "\n",
      "Site Id: 2 , CV RMSE: 0.8642784352110446 \n",
      "\n",
      "2 fold CV for site_id: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.307539\tvalid_1's rmse: 0.440731\n",
      "[202]\ttraining's rmse: 0.281544\tvalid_1's rmse: 0.436894\n",
      "[303]\ttraining's rmse: 0.266953\tvalid_1's rmse: 0.435269\n",
      "[404]\ttraining's rmse: 0.256983\tvalid_1's rmse: 0.434391\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's rmse: 0.256733\tvalid_1's rmse: 0.434369\n",
      "Site Id: 3 , Fold: 1 , RMSE: 0.4345179614319258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.32966\tvalid_1's rmse: 0.390334\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's rmse: 0.326849\tvalid_1's rmse: 0.389689\n",
      "Site Id: 3 , Fold: 2 , RMSE: 0.3900159254027245\n",
      "\n",
      "Site Id: 3 , CV RMSE: 0.4128669860599957 \n",
      "\n",
      "2 fold CV for site_id: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.142263\tvalid_1's rmse: 0.265089\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's rmse: 0.143932\tvalid_1's rmse: 0.264724\n",
      "Site Id: 4 , Fold: 1 , RMSE: 0.26405785082977123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.212279\tvalid_1's rmse: 0.315465\n",
      "[202]\ttraining's rmse: 0.188665\tvalid_1's rmse: 0.298443\n",
      "Early stopping, best iteration is:\n",
      "[216]\ttraining's rmse: 0.186879\tvalid_1's rmse: 0.297918\n",
      "Site Id: 4 , Fold: 2 , RMSE: 0.30966374580310735\n",
      "\n",
      "Site Id: 4 , CV RMSE: 0.2877656894503315 \n",
      "\n",
      "2 fold CV for site_id: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.507374\tvalid_1's rmse: 0.70752\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's rmse: 0.529147\tvalid_1's rmse: 0.706271\n",
      "Site Id: 5 , Fold: 1 , RMSE: 0.7037725134708636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.503428\tvalid_1's rmse: 0.64754\n",
      "[202]\ttraining's rmse: 0.448491\tvalid_1's rmse: 0.628246\n",
      "[303]\ttraining's rmse: 0.417892\tvalid_1's rmse: 0.618404\n",
      "[404]\ttraining's rmse: 0.397965\tvalid_1's rmse: 0.614329\n",
      "[505]\ttraining's rmse: 0.380305\tvalid_1's rmse: 0.609545\n",
      "[606]\ttraining's rmse: 0.367904\tvalid_1's rmse: 0.60632\n",
      "[707]\ttraining's rmse: 0.357034\tvalid_1's rmse: 0.603506\n",
      "[808]\ttraining's rmse: 0.347751\tvalid_1's rmse: 0.600737\n",
      "[909]\ttraining's rmse: 0.338945\tvalid_1's rmse: 0.598487\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\ttraining's rmse: 0.331496\tvalid_1's rmse: 0.596372\n",
      "Site Id: 5 , Fold: 2 , RMSE: 0.6129429913796911\n",
      "\n",
      "Site Id: 5 , CV RMSE: 0.6599222914095949 \n",
      "\n",
      "2 fold CV for site_id: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.989478\tvalid_1's rmse: 1.1223\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's rmse: 0.968779\tvalid_1's rmse: 1.121\n",
      "Site Id: 6 , Fold: 1 , RMSE: 1.122429072412157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's rmse: 0.894874\tvalid_1's rmse: 1.40703\n",
      "Site Id: 6 , Fold: 2 , RMSE: 1.3823946643109768\n",
      "\n",
      "Site Id: 6 , CV RMSE: 1.2591388040845908 \n",
      "\n",
      "2 fold CV for site_id: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 1.33545\tvalid_1's rmse: 1.71594\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's rmse: 1.38248\tvalid_1's rmse: 1.71341\n",
      "Site Id: 7 , Fold: 1 , RMSE: 1.6537947613359545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.985653\tvalid_1's rmse: 2.1427\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's rmse: 0.945448\tvalid_1's rmse: 2.13486\n",
      "Site Id: 7 , Fold: 2 , RMSE: 2.135872639795589\n",
      "\n",
      "Site Id: 7 , CV RMSE: 1.9101026233882594 \n",
      "\n",
      "2 fold CV for site_id: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.43747\tvalid_1's rmse: 0.510902\n",
      "[202]\ttraining's rmse: 0.400086\tvalid_1's rmse: 0.507124\n",
      "[303]\ttraining's rmse: 0.376101\tvalid_1's rmse: 0.505912\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's rmse: 0.372873\tvalid_1's rmse: 0.505469\n",
      "Site Id: 8 , Fold: 1 , RMSE: 0.504086438419819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.412876\tvalid_1's rmse: 0.655246\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's rmse: 0.392149\tvalid_1's rmse: 0.652085\n",
      "Site Id: 8 , Fold: 2 , RMSE: 0.6694145272396164\n",
      "\n",
      "Site Id: 8 , CV RMSE: 0.5925447683742928 \n",
      "\n",
      "2 fold CV for site_id: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.874373\tvalid_1's rmse: 0.953378\n",
      "[202]\ttraining's rmse: 0.767887\tvalid_1's rmse: 0.91065\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's rmse: 0.754711\tvalid_1's rmse: 0.90716\n",
      "Site Id: 9 , Fold: 1 , RMSE: 0.8759140190786968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.820918\tvalid_1's rmse: 1.04906\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's rmse: 0.785783\tvalid_1's rmse: 1.03309\n",
      "Site Id: 9 , Fold: 2 , RMSE: 1.010756912775909\n",
      "\n",
      "Site Id: 9 , CV RMSE: 0.9457417222984216 \n",
      "\n",
      "2 fold CV for site_id: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 1.08908\tvalid_1's rmse: 1.1839\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's rmse: 1.06961\tvalid_1's rmse: 1.17936\n",
      "Site Id: 10 , Fold: 1 , RMSE: 1.1837774059454662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.812435\tvalid_1's rmse: 1.44669\n",
      "[202]\ttraining's rmse: 0.753492\tvalid_1's rmse: 1.43685\n",
      "[303]\ttraining's rmse: 0.718702\tvalid_1's rmse: 1.43183\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's rmse: 0.708055\tvalid_1's rmse: 1.43116\n",
      "Site Id: 10 , Fold: 2 , RMSE: 1.4467305596718139\n",
      "\n",
      "Site Id: 10 , CV RMSE: 1.3218087187280503 \n",
      "\n",
      "2 fold CV for site_id: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.602756\tvalid_1's rmse: 0.745377\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's rmse: 0.611519\tvalid_1's rmse: 0.743517\n",
      "Site Id: 11 , Fold: 1 , RMSE: 0.7415924611053343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's rmse: 0.692995\tvalid_1's rmse: 1.8768\n",
      "Site Id: 11 , Fold: 2 , RMSE: 1.8768048628675664\n",
      "\n",
      "Site Id: 11 , CV RMSE: 1.4269427089346949 \n",
      "\n",
      "2 fold CV for site_id: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.375046\tvalid_1's rmse: 0.419332\n",
      "[202]\ttraining's rmse: 0.326673\tvalid_1's rmse: 0.399352\n",
      "[303]\ttraining's rmse: 0.302727\tvalid_1's rmse: 0.393964\n",
      "[404]\ttraining's rmse: 0.285654\tvalid_1's rmse: 0.390238\n",
      "Early stopping, best iteration is:\n",
      "[456]\ttraining's rmse: 0.276254\tvalid_1's rmse: 0.388712\n",
      "Site Id: 12 , Fold: 1 , RMSE: 0.38777628176749607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.330484\tvalid_1's rmse: 0.438018\n",
      "[202]\ttraining's rmse: 0.274905\tvalid_1's rmse: 0.421333\n",
      "[303]\ttraining's rmse: 0.24366\tvalid_1's rmse: 0.417539\n",
      "[404]\ttraining's rmse: 0.223276\tvalid_1's rmse: 0.415843\n",
      "[505]\ttraining's rmse: 0.20943\tvalid_1's rmse: 0.415203\n",
      "Early stopping, best iteration is:\n",
      "[578]\ttraining's rmse: 0.199969\tvalid_1's rmse: 0.414358\n",
      "Site Id: 12 , Fold: 2 , RMSE: 0.41487096231796045\n",
      "\n",
      "Site Id: 12 , CV RMSE: 0.40155217048045017 \n",
      "\n",
      "2 fold CV for site_id: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.866766\tvalid_1's rmse: 1.22354\n",
      "[202]\ttraining's rmse: 0.776637\tvalid_1's rmse: 1.20035\n",
      "Early stopping, best iteration is:\n",
      "[275]\ttraining's rmse: 0.750923\tvalid_1's rmse: 1.1935\n",
      "Site Id: 13 , Fold: 1 , RMSE: 1.1889348458158573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.859059\tvalid_1's rmse: 1.20044\n",
      "[202]\ttraining's rmse: 0.766175\tvalid_1's rmse: 1.18246\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's rmse: 0.769084\tvalid_1's rmse: 1.17979\n",
      "Site Id: 13 , Fold: 2 , RMSE: 1.1979158551571731\n",
      "\n",
      "Site Id: 13 , CV RMSE: 1.193433797017492 \n",
      "\n",
      "2 fold CV for site_id: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 1.22286\tvalid_1's rmse: 1.48521\n",
      "[202]\ttraining's rmse: 1.11915\tvalid_1's rmse: 1.4594\n",
      "[303]\ttraining's rmse: 1.0714\tvalid_1's rmse: 1.45231\n",
      "[404]\ttraining's rmse: 1.03407\tvalid_1's rmse: 1.4485\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttraining's rmse: 1.03551\tvalid_1's rmse: 1.44815\n",
      "Site Id: 14 , Fold: 1 , RMSE: 1.4443991430506828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 1.26678\tvalid_1's rmse: 1.53091\n",
      "[202]\ttraining's rmse: 1.18506\tvalid_1's rmse: 1.5091\n",
      "[303]\ttraining's rmse: 1.14805\tvalid_1's rmse: 1.50033\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttraining's rmse: 1.13743\tvalid_1's rmse: 1.49762\n",
      "Site Id: 14 , Fold: 2 , RMSE: 1.4908319353005135\n",
      "\n",
      "Site Id: 14 , CV RMSE: 1.4677991592444484 \n",
      "\n",
      "2 fold CV for site_id: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.514012\tvalid_1's rmse: 0.79727\n",
      "[202]\ttraining's rmse: 0.473464\tvalid_1's rmse: 0.778437\n",
      "[303]\ttraining's rmse: 0.456319\tvalid_1's rmse: 0.772179\n",
      "[404]\ttraining's rmse: 0.4432\tvalid_1's rmse: 0.769008\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's rmse: 0.442807\tvalid_1's rmse: 0.768982\n",
      "Site Id: 15 , Fold: 1 , RMSE: 0.7615222536286377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Solomonzhs\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 21 rounds\n",
      "[101]\ttraining's rmse: 0.616884\tvalid_1's rmse: 0.67931\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's rmse: 0.591666\tvalid_1's rmse: 0.66474\n",
      "Site Id: 15 , Fold: 2 , RMSE: 0.6566975159884169\n",
      "\n",
      "Site Id: 15 , CV RMSE: 0.71104422164764 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = 2\n",
    "models = {}\n",
    "cv_scores = {\"site_id\": [], \"cv_score\": []}\n",
    "\n",
    "for site_id in tqdm(range(16), desc=\"site_id\"):\n",
    "    print(cv, \"fold CV for site_id:\", site_id)\n",
    "    kf = KFold(n_splits=cv, random_state=seed)\n",
    "    models[site_id] = []\n",
    "\n",
    "    X_train_site = df_train[df_train.site_id==site_id].reset_index(drop=True)\n",
    "    y_train_site = X_train_site.log_meter_reading\n",
    "    y_pred_train_site = np.zeros(X_train_site.shape[0])\n",
    "    \n",
    "    score = 0\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(X_train_site, y_train_site)):\n",
    "        X_train, X_valid = X_train_site.loc[train_index, all_features], X_train_site.loc[valid_index, all_features]\n",
    "        y_train, y_valid = y_train_site.iloc[train_index], y_train_site.iloc[valid_index]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "        dvalid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=categorical_features)\n",
    "    \n",
    "        watchlist = [dtrain, dvalid]\n",
    "\n",
    "        params = {\"objective\": \"regression\",\n",
    "                  \"num_leaves\": 41,\n",
    "                  \"learning_rate\": 0.049,\n",
    "                  \"bagging_freq\": 5,\n",
    "                  \"bagging_fraction\": 0.51,\n",
    "                  \"feature_fraction\": 0.81,\n",
    "                  \"metric\": \"rmse\"\n",
    "                  }\n",
    "\n",
    "        model_lgb = lgb.train(params, train_set=dtrain, num_boost_round=999, valid_sets=watchlist, verbose_eval=101, early_stopping_rounds=21)\n",
    "        models[site_id].append(model_lgb)\n",
    "\n",
    "        y_pred_valid = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n",
    "        y_pred_train_site[valid_index] = y_pred_valid\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
    "        print(\"Site Id:\", site_id, \", Fold:\", fold+1, \", RMSE:\", rmse)\n",
    "        score += rmse / cv\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    cv_scores[\"site_id\"].append(site_id)\n",
    "    cv_scores[\"cv_score\"].append(score)\n",
    "        \n",
    "    print(\"\\nSite Id:\", site_id, \", CV RMSE:\", np.sqrt(mean_squared_error(y_train_site, y_pred_train_site)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:30:38.653517Z",
     "start_time": "2019-12-15T07:30:38.640565Z"
    }
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame.from_dict(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring and Average of 3 models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:30:43.714790Z",
     "start_time": "2019-12-15T07:30:42.077507Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_test = create_lag_features(weather_test, 18)\n",
    "weather_test.drop([\"air_temperature\", \"cloud_coverage\", \"dew_temperature\", \"precip_depth_1_hr\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T07:32:56.776468Z",
     "start_time": "2019-12-15T07:32:27.224245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2c7d27cfd84ce2af3bcd11fcb7dd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='site_id', max=16, style=ProgressStyle(description_width='initâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data for site_id 0\n",
      "Scoring for site_id 0\n",
      "Scoring for site_id 0 completed\n",
      "\n",
      "Preparing test data for site_id 1\n",
      "Scoring for site_id 1\n",
      "Scoring for site_id 1 completed\n",
      "\n",
      "Preparing test data for site_id 2\n",
      "Scoring for site_id 2\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (5063280, 40) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1da9387b3514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mmodel_lgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msite_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0my_pred_test_site\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_site\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2363\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2364\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2365\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2367\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# change non-float data to float data, need to copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (5063280, 40) and data type float64"
     ]
    }
   ],
   "source": [
    "df_test_sites = []\n",
    "\n",
    "for site_id in tqdm(range(16), desc=\"site_id\"):\n",
    "    print(\"Preparing test data for site_id\", site_id)\n",
    "\n",
    "    X_test_site = df_test[df_test.site_id==site_id]\n",
    "    weather_test_site = weather_test[weather_test.site_id==site_id]\n",
    "    \n",
    "    X_test_site = X_test_site.merge(weather_test_site, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
    "    \n",
    "    row_ids_site = X_test_site.row_id\n",
    "\n",
    "    X_test_site = X_test_site[all_features]\n",
    "    y_pred_test_site = np.zeros(X_test_site.shape[0])\n",
    "    \n",
    "    print(\"Scoring for site_id\", site_id)    \n",
    "    \n",
    "    for fold in range(cv):\n",
    "        model_lgb = models[site_id][fold]\n",
    "        y_pred_test_site += model_lgb.predict(X_test_site, num_iteration=model_lgb.best_iteration) / cv\n",
    "        gc.collect()\n",
    "        \n",
    "    df_test_site = pd.DataFrame({\"row_id\": row_ids_site, \"meter_reading\": y_pred_test_site})\n",
    "    df_test_sites.append(df_test_site)\n",
    "    \n",
    "    print(\"Scoring for site_id\", site_id, \"completed\\n\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(energy,building_info,on='building_id',how='left')\n",
    "data = pd.merge(data,weather,on=['site_id','timestamp', 'year', 'month', 'day', 'hour', 'minute', \n",
    "                                  'second'],how='left')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['primary_use'] = data['primary_use'].astype('category').cat.codes\n",
    "data['meter'] = data['meter'].astype('category').cat.codes\n",
    "#data = dt_parts(data,'timestamp')\n",
    "#data.fillna(0,inplace=True)\n",
    "cols = data.columns\n",
    "for col in cols:\n",
    "    data[col].fillna(data[col].mean(),inplace=True)\n",
    "data = df_type_optimize(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per the discussion in the following thread, https://www.kaggle.com/c/ashrae-energy-prediction/discussion/117083, there is some discrepancy in the meter_readings for different ste_id's and buildings. It makes sense to delete them\n",
    "idx_to_drop = list((data[(data['site_id'] == 0) & (data['timestamp'] < \"2016-05-21 00:00:00\")]).index)\n",
    "data.drop(idx_to_drop,axis='rows',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "number_unique_meter_per_building = data.groupby('building_id')['meter'].nunique()\n",
    "data['number_unique_meter_per_building'] = data['building_id'].map(number_unique_meter_per_building)\n",
    "\n",
    "mean_meter_reading_per_building = data.groupby('building_id')['meter_reading'].mean()\n",
    "data['mean_meter_reading_per_building'] = data['building_id'].map(mean_meter_reading_per_building)\n",
    "median_meter_reading_per_building = data.groupby('building_id')['meter_reading'].median()\n",
    "data['median_meter_reading_per_building'] = data['building_id'].map(median_meter_reading_per_building)\n",
    "std_meter_reading_per_building = data.groupby('building_id')['meter_reading'].std()\n",
    "data['std_meter_reading_per_building'] = data['building_id'].map(std_meter_reading_per_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_meter_reading_per_meter = data.groupby('meter')['meter_reading'].mean()\n",
    "data['mean_meter_reading_per_meter'] = data['meter'].map(mean_meter_reading_per_meter)\n",
    "median_meter_reading_per_meter = data.groupby('meter')['meter_reading'].median()\n",
    "data['median_meter_reading_per_meter'] = data['meter'].map(median_meter_reading_per_meter)\n",
    "std_meter_reading_per_meter = data.groupby('meter')['meter_reading'].std()\n",
    "data['std_meter_reading_per_meter'] = data['meter'].map(std_meter_reading_per_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_meter_reading_per_primary_usage = data.groupby('primary_use')['meter_reading'].mean()\n",
    "data['mean_meter_reading_per_primary_usage'] = data['primary_use'].map(mean_meter_reading_per_primary_usage)\n",
    "median_meter_reading_per_primary_usage = data.groupby('primary_use')['meter_reading'].median()\n",
    "data['median_meter_reading_per_primary_usage'] = data['primary_use'].map(median_meter_reading_per_primary_usage)\n",
    "std_meter_reading_per_primary_usage = data.groupby('primary_use')['meter_reading'].std()\n",
    "data['std_meter_reading_per_primary_usage'] = data['primary_use'].map(std_meter_reading_per_primary_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_meter_reading_per_site_id = data.groupby('site_id')['meter_reading'].mean()\n",
    "data['mean_meter_reading_per_site_id'] = data['site_id'].map(mean_meter_reading_per_site_id)\n",
    "median_meter_reading_per_site_id = data.groupby('site_id')['meter_reading'].median()\n",
    "data['median_meter_reading_per_site_id'] = data['site_id'].map(median_meter_reading_per_site_id)\n",
    "std_meter_reading_per_site_id = data.groupby('site_id')['meter_reading'].std()\n",
    "data['std_meter_reading_per_site_id'] = data['site_id'].map(std_meter_reading_per_site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Let's check the correlation between the variables and eliminate the one's that have high correlation\n",
    "# Threshold for removing correlated variables\n",
    "threshold = 0.9\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = data.corr().abs()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with upperelations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))\n",
    "print (\"Following columns can be dropped {}\".format(to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['building_id','Month','meter','Hour','primary_use','DayOfWeek','DayOfMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'meter_reading'\n",
    "y = np.log1p(data[target_col])\n",
    "# Converting the dependent variable to logarithmic scale\n",
    "data.drop('timestamp',axis=1,inplace=True)\n",
    "Xs = data.drop(target_col,axis=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(Xs, y, test_size=0.2, random_state=0)\n",
    "X_train.shape,X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code reference above\n",
    "from sklearn.ensemble import forest\n",
    "def set_rf_samples(n):\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n))\n",
    "#set_rf_samples(130000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = RandomForestRegressor(n_estimators=60,\n",
    "                              random_state=0,n_jobs=-1)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(actual,preds):\n",
    "    return np.sqrt(mean_squared_error(actual,preds))\n",
    "\n",
    "def get_evaluations(model):\n",
    "    preds = model.predict(X_train)\n",
    "    plt.hist(np.log1p(preds),bins=100)\n",
    "    plt.show();\n",
    "    print('train_rmse: ',RMSE(y_train,preds))\n",
    "                    \n",
    "    preds = model.predict(X_valid)\n",
    "    plt.hist(np.log1p(preds),bins=100)\n",
    "    plt.show()\n",
    "    print('valid_rmse: ',RMSE(y_valid,preds))\n",
    "    \n",
    "get_evaluations(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(model,feature_names=list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out sample out validation set\n",
    "test_row = X_valid.loc[15256244,:]\n",
    "test_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(model,test_row,feature_names=list(X_train.columns))\n",
    "#bias seems to be high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_test = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\test.csv')\n",
    "weather_test = pd.read_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\weather_test.csv')\n",
    "test = pd.merge(energy_test,building_info,on='building_id',how='left')\n",
    "test = pd.merge(test,weather_test,on=['site_id','timestamp'],how='left')\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['primary_use'] = test['primary_use'].astype('category').cat.codes\n",
    "test = dt_parts(test,'timestamp')\n",
    "test.fillna(0,inplace=True)\n",
    "test=df_type_optimize(test)\n",
    "ids = test['row_id']\n",
    "test.drop('row_id',axis=1,inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = model.predict(test)\n",
    "\n",
    "sub_df = pd.DataFrame()\n",
    "sub_df['row_id'] = ids\n",
    "sub_df['meter_reading'] = preds\n",
    "sub_df.to_csv(r'C:\\Users\\Solomonzhs\\Desktop\\Learn\\ashrae-energy-prediction\\the-sub-mission.csv',index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(sub_df['meter_reading']),bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
